%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCTION
\chapter{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Problem: large systems are difficult to manage
Systems that process and store large amounts of data (petabytes and beyond) are
difficult to manage. Computing has reached an era where the data is too large,
the software is too complicated, the hardware is too fast, and the events are
too frequent for any human to manage. These drastic changes should alter how
large systems are designed and deployed. We argue that the most elegant and
future-proof solution for improving and maintaining performance in these large
systems is to improve the communication between applications and the storage.
Our solution is  motivated by three trends that lead to more software layers:
(1) more data, (2) extreme heterogeneity, and (3) open-source software.  The
proliferation of large complex stacks composed of many layers makes this thesis
an especially timely solution.

% Timeliness: layers on layers; {big stacks, overhead, proof}
The overwhelming volume, velocity, and veracity of today's data shapes
modern software. When data grows too large, we scale to larger systems, either
by scaling out or up. Focusing on the scale-out model has given birth to
stacks, like Apache, that are used in industry, laboratories, and academia. But
the size of these stacks leads to increased complexity, as code bases are
larger and there are more layers~\cite{sevilla:eurosys17-malacology}, resulting
in reduced performance, redundant code, and longer code paths. The overhead of
these stacks are so high that many workloads can be outperformed by a single
node with less resources~\cite{sevilla:discs2013-framework,
rowstron:hotcdp2012-hadoop-vs-single-node, schwarzkopf:hotcloud2012-7-sins,
gigaspaces:whitepaper2011-su-vs-so, michael:2007pdps-scale-up-x-scale-out}.

% Timeliness: extreme hetoregeneity {memory wall, more hardware, more runtimes}
Extreme heterogeneity in both software and hardware has also lead to larger
software stacks that manage resources. Data centers are larger and have faster
devices because device and network speeds are scaling much faster than DRAM
speeds. The so-called memory wall~\cite{wulf:sigarch1995-memory-wall} pushes
resource management into software runtimes, which must now manage large numbers
of heterogeneous devices. The increasing momentum behind disaggregated
storage~\cite{klimovic:asplos2017-reflex, klimovic:eurosys16-disagg}, a model
that uses software as the control plane and reduces the CPU requirements of
devices, is result of prognoses we are heading towards data centers that need
to provision a CPU per storage device~\cite{samuels:oss16}. Regardless of where
the future leads, the scale and complexity of software will continue to scale
with the size of the architectures they manage.

% Timeliness: oss faciliates transparency {vendor lock in, efficiency, collab}
Finally, the last trend that has lead to the explosion of software is
open-source software. Open-source software is gaining traction because it helps
consumers avoid vendor lock in, it leads to more efficient implementations, and
it encourages collaboration. All these advantages are rooted in transparency,
as developers can work together to write code that manages the extreme
heterogeneity mentioned above, but it also lets developers see the source code
for the systems they use ``off-the-shelf". In short, open-source software leads
to more software because (1) code can come from different domains,
organizations, and communities, and (2) it easier to write optimizations
because functionality is fully exposed.

In light of these trends, our solution is a concept called ``programmable
storage"~\cite{sevilla:eurosys17-malacology, watkins:hot17-declstor}.
Programmable storage facilitates the re-use and extension of existing storage
abstractions provided by the underlying software stack, to enable the creation
of new services via composition. This process is faster than reducing layers
manually for new architectures with less layers~\cite{bent:login16-hpc-trends}
that may break backwards compatibility.  We add interfaces {\it into} a storage
system's internal functionality to facilitate application co-design, leading to
more efficient implementations that inherit the robustness of the underlying
system with less code duplication. My thesis uses the programmable storage
approach to embed policy engines into the metadata substrates to control the
behavior, performance, and transparency of the entire software stack.

