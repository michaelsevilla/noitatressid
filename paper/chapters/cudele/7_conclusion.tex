%\section{Discussion}
%
%% Could we have implemented this on something other than CephFS?
%One question that comes up often in our work with Ceph is: ``Why do we always
%choose Ceph and can we implement this on another storage system?" Ceph is
%popular, robust, and open source -- getting it merged into mainline has a
%better chance of getting used than if we had built the system `clean-slate'
%from the ground up. Using Ceph, we can also leverage its robustness using an
%approach called ``programmability".
%
%% How awesome programmability is
%``Programmability" is a way of designing storage systems that encourages code
%re-use and composition.  A programmable storage system exposes internal
%subsystem as building blocks for higher level services. This `dirty-slate'
%approach limits redundant code and leverages the robustness of the underlying
%storage system. Cudele uses this approach and re-uses some of the building
%blocks from the Malacology programmable storage system~\cite{sevilla:eurosys17}
%to great success and requires only:
%
%\begin{itemize}
%
%  \item 354 lines of library code
%
%  \item 219 lines of non-destructive metadata server code, which is not used
%  unless it is turned on
%
%  \item 4 lines of destructive client/server code to check whether a namespace
%  is decoupled
%
%\end{itemize}

\section{Conclusion}

Relaxing consistency/durability semantics in file systems is a double-edged
sword. While the technique performs and scales better, applications that rely
on strong consistency and durability are no longer compatible.  Cudele lets
\oldcomment{users}\newcomment{administrators} assign consistency/durability
guarantees to subtrees in the global namespace, resulting in 
custom fit semantics for applications. We show how applications can co-exist and
perform well in a global namespace and our prototype enables studies that
adjust these semantics over {\it time and space}, where subtrees can change
without ever moving the data they reference.


